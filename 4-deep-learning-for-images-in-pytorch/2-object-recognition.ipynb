{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.ops import nms\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16, VGG16_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"images/cat.jpeg\")\n",
    "bbox = [10, 10, 200, 200]\n",
    "\n",
    "# Convert bbox into tensors\n",
    "bbox_tensor = torch.tensor(bbox)\n",
    "\n",
    "# Add a new batch dimension\n",
    "bbox_tensor = bbox_tensor.unsqueeze(0)\n",
    "\n",
    "# Resize the image and transform to tensor\n",
    "transform = transforms.Compose([\n",
    "  transforms.Resize(224),\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Apply transform to image\n",
    "image_tensor = transform(image)\n",
    "print(image_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing a bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox= [50, 25, 160, 160]\n",
    "bbox_tensor = torch.tensor(bbox).unsqueeze(0)\n",
    "\n",
    "# Implement draw_bounding_boxes\n",
    "image_tensor = (image_tensor * 255).type(torch.uint8)\n",
    "img_bbox = draw_bounding_boxes(image_tensor, bbox_tensor, width=3, colors=\"red\")\n",
    "\n",
    "# Tranform tensors to image\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage()\n",
    "])\n",
    "\n",
    "plt.imshow(transform(img_bbox))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating object recognition models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounding boxes prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model's prediction\n",
    "with torch.no_grad():\n",
    "    output = model(test_image)\n",
    "\n",
    "# Extract boxes from the output\n",
    "boxes = output[0][\"boxes\"]\n",
    "\n",
    "# Extract scores from the output\n",
    "scores = output[0][\"scores\"]\n",
    "\n",
    "print(boxes, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the IoU threshold\n",
    "iou_threshold = 0.5\n",
    "\n",
    "# Apply non-max suppression\n",
    "box_indices = nms(boxes=boxes, scores=scores, iou_threshold=0.5)\n",
    "\n",
    "# Filter boxes\n",
    "filtered_boxes = boxes[box_indices]\n",
    "\n",
    "print(\"Filtered Boxes:\", filtered_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection using R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained model backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained weights\n",
    "vgg_model = vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "\n",
    "# Extract the input dimension\n",
    "input_dim = nn.Sequential(*list(vgg_model.classifier.children()))[0].in_features\n",
    "\n",
    "# Create a backbone with convolutional layers\n",
    "backbone = nn.Sequential(*list(vgg_model.features.children()))\n",
    "\n",
    "# Print the backbone model\n",
    "print(backbone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable with the number of classes\n",
    "num_classes = 2\n",
    "    \n",
    "# Create a sequential block\n",
    "classifier = nn.Sequential(\n",
    "\t# Create a linear layer with input features\n",
    "\tnn.Linear(input_dim, 512),\n",
    "\tnn.ReLU(),\n",
    "\t# Add the output dimension to the classifier\n",
    "\tnn.Linear(512, num_classes),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box regressor block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of coordinates\n",
    "num_coordinates = 4\n",
    "\n",
    "bb = nn.Sequential(  \n",
    "\t# Add input and output dimensions\n",
    "\tnn.Linear(input_dim, 32),\n",
    "\tnn.ReLU(),\n",
    "\t# Add the output for the last regression layer\n",
    "\tnn.Linear(32, num_coordinates),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-in-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
